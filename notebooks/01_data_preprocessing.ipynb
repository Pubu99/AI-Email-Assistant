{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 01_data_preprocessing.ipynb ===\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/raw/emails.csv\")\n",
    "df = df[[\"file\", \"message\"]].dropna()\n",
    "print(f\"ðŸ“¥ Loaded {len(df)} emails.\")\n",
    "\n",
    "# Extract main email body (remove headers & long quotes)\n",
    "def extract_body_from_message(message):\n",
    "    try:\n",
    "        body = re.split(r'\\n\\s*\\n', message, maxsplit=1)[-1]  # remove headers\n",
    "        body = re.sub(r'\\s+', ' ', body)  # normalize spaces\n",
    "        body = re.split(r'(-----Original Message-----|_+Forwarded by|From:.*@)', body)[0]  # cut long reply chains\n",
    "        return body.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df[\"clean_body\"] = df[\"message\"].progress_apply(extract_body_from_message)\n",
    "\n",
    "# Remove very long or very short messages\n",
    "df = df[df[\"clean_body\"].str.len() > 100]        # too short = useless\n",
    "df = df[df[\"clean_body\"].str.len() < 100000]     # too long = spaCy crash\n",
    "\n",
    "# (Removed sampling step to use full dataset)\n",
    "\n",
    "# Heuristic intent labeling using keywords\n",
    "INTENT_KEYWORDS = {\n",
    "    \"Meeting Request\": [\"schedule\", \"meeting\", \"calendar\", \"call\", \"appointment\"],\n",
    "    \"Job Inquiry\": [\"job\", \"resume\", \"position\", \"career\", \"apply\"],\n",
    "    \"Finance\": [\"invoice\", \"payment\", \"amount\", \"fund\", \"salary\", \"finance\"],\n",
    "    \"Legal\": [\"contract\", \"agreement\", \"terms\", \"clause\", \"lawyer\"],\n",
    "    \"Appreciation\": [\"thank\", \"thanks\", \"grateful\", \"appreciate\", \"gratitude\"],\n",
    "    \"Complaint\": [\"issue\", \"problem\", \"complaint\", \"error\", \"concern\"],\n",
    "    \"Technical Support\": [\"bug\", \"support\", \"crash\", \"error\", \"fix\", \"install\"],\n",
    "    \"Data Request\": [\"send\", \"forward\", \"email\", \"attach\", \"request\"],\n",
    "    \"Greeting\": [\"hello\", \"hi\", \"greetings\", \"good morning\"],\n",
    "    \"Farewell\": [\"regards\", \"bye\", \"sincerely\", \"take care\"],\n",
    "    \"Sales Inquiry\": [\"quote\", \"pricing\", \"discount\", \"offer\", \"deal\"],\n",
    "    \"Project Update\": [\"progress\", \"update\", \"status\", \"report\"],\n",
    "    \"Reminder\": [\"remind\", \"deadline\", \"follow up\", \"due\"],\n",
    "    \"Event Planning\": [\"venue\", \"event\", \"conference\", \"webinar\", \"party\"],\n",
    "    \"Personal\": [\"family\", \"friend\", \"wedding\", \"vacation\", \"holiday\"]\n",
    "}\n",
    "\n",
    "def assign_label(text):\n",
    "    text = text.lower()\n",
    "    for label, keywords in INTENT_KEYWORDS.items():\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return label\n",
    "    return \"General Inquiry\"\n",
    "\n",
    "df[\"label\"] = df[\"clean_body\"].progress_apply(assign_label)\n",
    "\n",
    "# Load spaCy model and set max length\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 300000  # increase limit to avoid crash on long text\n",
    "\n",
    "# ðŸ”Ž Extract named entities: PERSON, DATE, ORG, GPE\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        \"PERSON\": list(set(ent.text for ent in doc.ents if ent.label_ == \"PERSON\")),\n",
    "        \"DATE\": list(set(ent.text for ent in doc.ents if ent.label_ == \"DATE\")),\n",
    "        \"ORG\": list(set(ent.text for ent in doc.ents if ent.label_ == \"ORG\")),\n",
    "        \"GPE\": list(set(ent.text for ent in doc.ents if ent.label_ == \"GPE\"))\n",
    "    }\n",
    "\n",
    "df[\"entities\"] = df[\"clean_body\"].progress_apply(extract_entities)\n",
    "\n",
    "# Save cleaned dataset\n",
    "os.makedirs(\"../data/processed/\", exist_ok=True)\n",
    "df.to_csv(\"../data/processed/clean_emails.csv\", index=False)\n",
    "print(\"âœ… Cleaned data saved to: data/processed/clean_emails.csv\")\n",
    "\n",
    "# Preview\n",
    "df[[\"file\", \"label\", \"clean_body\", \"entities\"]].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
